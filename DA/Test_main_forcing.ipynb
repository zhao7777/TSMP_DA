{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b97a0d2d-1195-49d8-a2b5-35fe5017b51c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import xarray as xr\n",
    "import netCDF4\n",
    "\n",
    "sys.path.append('/p/project/cjibg36/jibg3674/eCLM_PyDA/TSMP_DA/DA')\n",
    "\n",
    "# from setup_parameters import setup_Ks,setup_Ks_tensor,setup_Ks_anom\n",
    "# from generate_parameters import generate_Ks,generate_Ks_tensor,generate_Ks_anom\n",
    "from run_realization_v2 import setup_submit_wait\n",
    "from DA_operators import operator_clm_SMAP, operator_clm_FLX\n",
    "\n",
    "from settings import settings_run,settings_clm,settings_pfl,settings_sbatch,settings_DA,settings_gen,date_results_binned,freq_output,date_range_noleap\n",
    "\n",
    "# from multiprocessing import Pool\n",
    "import multiprocessing as mp\n",
    "\n",
    "from itertools import repeat\n",
    "from scipy import sparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import time\n",
    "\n",
    "from helpers import haversine_distance\n",
    "\n",
    "os.environ['MKL_NUM_THREADS'] = '4'\n",
    "os.nice(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7d2d00c-3a31-425d-bec3-34d0fa374a64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def realize_parameters(i_real,settings_gen,settings_run,init=True,run_prior=False):\n",
    "    dir_real = os.path.join(settings_run['dir_iter'],'R%3.3i'%i_real)\n",
    "    local_state = np.random.RandomState() #required for parallel processes in python\n",
    "    dir_DA = settings_run['dir_DA']\n",
    "\n",
    "    if not os.path.exists(dir_real):\n",
    "        print('Creating parameter realizations for ensemble member %i' % i_real)\n",
    "        print('Creating folder for realization %i: %s' % (i_real,dir_real), flush=True )\n",
    "        os.mkdir(dir_real)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        if init:\n",
    "            print('Initializing parameters from prior parameter settings')\n",
    "            i_iter_ = 0 #prior parameters are always read from the initial iteration file\n",
    "            # Read parameter values + std, generate parameter realizations (i_real)\n",
    "            for p_name, p_fn_gen in zip(settings_gen['param_names'],settings_gen['param_gen']):\n",
    "                p_values = np.load(os.path.join(dir_DA,'%s.param.%3.3i.%3.3i.prior.npy'% (p_name,settings_gen['i_date'],i_iter_) ))\n",
    "                p_mean = p_values[:,0]\n",
    "                p_sigma = p_values[:,1]\n",
    "                \n",
    "                # ensemble member 0: most likely parameter values are used\n",
    "                if i_real == 0 or run_prior:\n",
    "                    p_real = p_mean.copy()\n",
    "                else:\n",
    "                    p_real = local_state.normal(p_mean,p_sigma)\n",
    "                np.save(os.path.join(dir_DA,'%s.param.%3.3i.%3.3i.%3.3i'%(p_name,settings_gen['i_date'],settings_gen['i_iter'],i_real)),p_real)\n",
    "                p_fn_gen(i_real,settings_gen,settings_run)\n",
    "        else:\n",
    "            print('Updating parameters from DA analysis')\n",
    "            for p_name, p_fn_gen in zip(settings_gen['param_names'],settings_gen['param_gen']):\n",
    "                print('Debug: realize_parameters, i_real %i, %s, %s' % (i_real,p_name, p_fn_gen) )\n",
    "                p_fn_gen(i_real,settings_gen,settings_run)\n",
    "            \n",
    "def worker_realize_parameters(*args, **kwargs):\n",
    "    try:\n",
    "        realize_parameters(*args, **kwargs)\n",
    "    except Exception as e:\n",
    "        print(f\"Exception in worker: {e}\")\n",
    "        \n",
    "            \n",
    "def read_parameters(n_ensemble,settings_gen,settings_run):\n",
    "    # read parameter values of the different ensemble members into an array\n",
    "    param_names = []\n",
    "    param_latlon = np.array([])\n",
    "    param_r_loc = np.array([])\n",
    "    param_lengths_old = []\n",
    "    for i1 in np.arange(n_ensemble):\n",
    "        param_tmp = np.array([])\n",
    "        \n",
    "        if i1 == 0:\n",
    "            for i2,p_name in enumerate(settings_gen['param_names']):\n",
    "                param_ = np.load(os.path.join(settings_run['dir_DA'],'%s.param.%3.3i.%3.3i.%3.3i.npy'% (p_name,settings_gen['i_date'],settings_gen['i_iter'],i1+1) ))\n",
    "                # settings_gen['param_length'][p_name] = len(param_)\n",
    "                param_lengths_old.append(len(param_))\n",
    "                param_tmp = np.append(param_tmp,param_)\n",
    "                param_names.extend([p_name + '_%i'%int_ for int_ in np.arange(len(param_))])\n",
    "                param_r_loc = np.append(param_r_loc,settings_gen['param_r_loc'][i2]*np.ones(len(param_)))\n",
    "                file_latlon = os.path.join(settings_run['dir_DA'],'%s.latlon.npy'% (p_name))\n",
    "                if os.path.exists(file_latlon):\n",
    "                    if len(param_latlon) == 0:\n",
    "                        param_latlon = np.load(file_latlon)\n",
    "                    else:\n",
    "                        param_latlon = np.vstack((param_latlon,np.load(file_latlon)))\n",
    "                else:\n",
    "                    if len(param_latlon) == 0:\n",
    "                        param_latlon = np.nan*np.zeros([len(param_),2])\n",
    "                    else:\n",
    "                        param_latlon = np.vstack((param_latlon,np.nan*np.zeros([len(param_),2])))\n",
    "            param_all = param_tmp.copy()\n",
    "            \n",
    "        else:\n",
    "            param_lengths = []\n",
    "            for i2,p_name in enumerate(settings_gen['param_names']):\n",
    "                param_ = np.load(os.path.join(settings_run['dir_DA'],'%s.param.%3.3i.%3.3i.%3.3i.npy'% (p_name,settings_gen['i_date'],settings_gen['i_iter'],i1+1) ))\n",
    "                param_lengths.append(len(param_))\n",
    "                param_tmp = np.append(param_tmp,param_)        \n",
    "            param_all = np.vstack((param_all,param_tmp))\n",
    "            \n",
    "            if param_lengths != param_lengths_old:\n",
    "                raise RuntimeError('parameter lengths not equal\\n%s\\n%s' % (param_lengths,param_lengths_old))\n",
    "                \n",
    "    return param_all.T,param_names,param_latlon,param_r_loc\n",
    "\n",
    "\n",
    "def write_parameters(parameters,settings_gen,settings_run):\n",
    "    dir_DA = settings_run['dir_DA']\n",
    "    for i_real in range(parameters.shape[1]):\n",
    "        i_start = 0\n",
    "        for p_name in settings_gen['param_names']:\n",
    "            i_end = i_start + settings_gen['param_length'][p_name] \n",
    "            param_ = parameters[i_start:i_end,i_real]\n",
    "            np.save(os.path.join(dir_DA,'%s.param.%3.3i.%3.3i.%3.3i'%(p_name,settings_gen['i_date'],settings_gen['i_iter']+1,i_real+1)),param_)\n",
    "            i_start = i_end\n",
    "            \n",
    "    # write mean parameter values to member 0\n",
    "    i_start = 0\n",
    "    for p_name in settings_gen['param_names']:\n",
    "        i_end = i_start + settings_gen['param_length'][p_name] \n",
    "        param_ = parameters[i_start:i_end,:].mean(axis=1)\n",
    "        np.save(os.path.join(dir_DA,'%s.param.%3.3i.%3.3i.%3.3i'%(p_name,settings_gen['i_date'],settings_gen['i_iter']+1,0)),param_)\n",
    "        i_start = i_end   \n",
    "        \n",
    "def change_setting(filename, key, new_value):\n",
    "    # Escape special characters in the key\n",
    "    escaped_key = re.escape(key)\n",
    "\n",
    "    # Define the pattern to match\n",
    "    pattern = re.compile(r\"('{}'\\s*:\\s*)(.+?)(?=[,}}])\".format(escaped_key))\n",
    "\n",
    "    # Read the content of the file\n",
    "    with open(filename, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Use the pattern to find and replace the matched value\n",
    "    content = pattern.sub(r\"\\g<1>{}\".format(new_value), content)\n",
    "\n",
    "    # Write the updated content back to the file\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(content)\n",
    "        \n",
    "def check_for_success(dir_iter,dir_DA,dir_settings,date_results_iter,n_ensemble):\n",
    "        \n",
    "    date_start_sim = date_results_iter[-1][0]\n",
    "    date_end_sim = date_results_iter[-1][-1]\n",
    "    str_date = str(date_start_sim.date()).replace('-','') + '-' + str(date_end_sim.date()).replace('-','')\n",
    "    all_success = False\n",
    "    reread_required = False\n",
    "\n",
    "    ## Following function should be called iteratively until np.all(flag_success) = True\n",
    "    while not all_success:\n",
    "        reread_required = True\n",
    "        i_source = n_ensemble #which directory to move in case one of the runs failed\n",
    "\n",
    "        flag_success = np.zeros(n_ensemble,dtype=bool)\n",
    "        for i1 in range(1,n_ensemble+2):\n",
    "            restart_file = glob(os.path.join(dir_iter,'R%3.3i/run_%s/*.clm2.r.*.nc'%(i1,str_date)))\n",
    "            print('Restart file: %i, %s' %(i1,restart_file) )\n",
    "            if len(restart_file) > 0:\n",
    "                flag_success[i1-1] = True\n",
    "\n",
    "\n",
    "        # if the last run failed, remove it\n",
    "        while flag_success[-1] == False:\n",
    "            # remove last folder\n",
    "            shutil.rmtree(os.path.join(dir_iter,'R%3.3i'%(i_source)), ignore_errors = True) \n",
    "            # remove last index flag\n",
    "            flag_success = np.delete(flag_success,-1)\n",
    "            i_source -= 1\n",
    "            n_ensemble -= 1\n",
    "\n",
    "        if not np.all(flag_success):\n",
    "            i_dest = np.where(~flag_success)[0][0]+1 \n",
    "\n",
    "            print('-----------------Important!!!!!-----------------')\n",
    "            print('Moving R%3.3i to R%3.3i (failed run)' %(i_source,i_dest) )\n",
    "            print('-----------------Important!!!!!-----------------')\n",
    "\n",
    "            paramfiles_source = sorted(glob(os.path.join(dir_DA,'*.%3.3i.npy'%i_source)))\n",
    "            paramfiles_source_tmp = sorted([file_ + '_old' for file_ in paramfiles_source])\n",
    "            paramfiles_dest = sorted(glob(os.path.join(dir_DA,'*.%3.3i.npy'%i_dest)))\n",
    "            paramfiles_dest_tmp = sorted([file_ + '_old' for file_ in paramfiles_dest])\n",
    "\n",
    "            shutil.move(os.path.join(dir_iter,'R%3.3i'%i_dest),os.path.join(dir_iter,'R%3.3i_old'%i_dest) )\n",
    "            shutil.move(os.path.join(dir_iter,'R%3.3i'%i_source),os.path.join(dir_iter,'R%3.3i'%i_dest) )\n",
    "\n",
    "            for file_src_in,file_src_out,file_dest_in,file_dest_out in zip(paramfiles_source,paramfiles_source_tmp,paramfiles_dest,paramfiles_dest_tmp):\n",
    "                shutil.move(file_dest_in,file_dest_out) #move failed parameter file (e.g. 13) to 13_old\n",
    "                shutil.copy(file_src_in,file_src_out) #copy the successfull parameter file (e.g. 16) to 16_old\n",
    "                shutil.move(file_src_in,file_dest_in) #move the successfull paramfile (e.g. 16) to 13\n",
    "\n",
    "            n_ensemble -=1\n",
    "\n",
    "        else:\n",
    "            all_success = True\n",
    "            \n",
    "    if not reread_required:\n",
    "        print('Simulations were all successfull, all restart files available')\n",
    "    else:\n",
    "        change_setting(os.path.join(dir_settings,'settings.py'),'n_ensemble',n_ensemble)\n",
    "        \n",
    "    return n_ensemble, reread_required\n",
    "\n",
    "def mask_observations(data_names,data_measured,data_var,data_latlon,data_nselect,data_mask,factor_inflate=1.):\n",
    "    data_indices = {}\n",
    "    i_start = 0\n",
    "    i_end = np.inf\n",
    "    \n",
    "    # print(factor_inflate)\n",
    "    n_vars = len(data_names)\n",
    "    if type(factor_inflate) == float:\n",
    "        var_inflate = {var_ : factor_inflate for var_ in data_names}\n",
    "    elif type(factor_inflate) == dict:\n",
    "        var_inflate = factor_inflate.copy()\n",
    "    else:\n",
    "        raise RuntimeError('type should be float or dict')\n",
    "        \n",
    "    for i1,var_ in enumerate(data_names):\n",
    "        # print(var_,data_var[var_],var_inflate[var_])\n",
    "        data_var[var_] *= var_inflate[var_]\n",
    "        \n",
    "        n_select = data_nselect[var_]\n",
    "        if len(data_measured[var_]) < n_select:\n",
    "            data_mask[var_] = np.ones(len(data_measured[var_]),dtype=bool)\n",
    "            n_select = len(data_measured[var_])\n",
    "        else:\n",
    "            frac_select = min((n_select / len(data_measured[var_])),.99)\n",
    "            data_mask[var_] = np.random.choice([0,1],size=len(data_measured[var_]),p=[1-frac_select,frac_select]).astype(bool) \n",
    "            n_select = int(data_mask[var_].sum())\n",
    "        i_end = i_start + n_select\n",
    "        data_indices[var_] = [i_start,i_end]\n",
    "\n",
    "        if i1 == 0:\n",
    "            data_measured_masked = data_measured[var_][data_mask[var_]].copy()\n",
    "            data_latlon_masked = data_latlon[var_][data_mask[var_]].copy()\n",
    "            if type(data_var[var_]) == float:\n",
    "                data_var_masked = data_var[var_]*np.ones(n_select)\n",
    "            else:\n",
    "                data_var_masked = data_var[var_][data_mask[var_]].copy()\n",
    "        else:\n",
    "            data_measured_masked = np.append(data_measured_masked,data_measured[var_][data_mask[var_]])\n",
    "            data_latlon_masked = np.vstack((data_latlon_masked,data_latlon[var_][data_mask[var_]]))\n",
    "            if type(data_var[var_]) == float:\n",
    "                data_var_masked = np.append(data_var_masked,data_var[var_]*np.ones(n_select))\n",
    "            else:\n",
    "                data_var_masked = np.append(data_var_masked,data_var[var_][data_mask[var_]])\n",
    "\n",
    "        i_start = i_end\n",
    "        print('Thinned out %s observations: %i -> %i' % (var_,len(data_measured[var_]),n_select))\n",
    "\n",
    "    n_data = i_end\n",
    "    # data_var_masked*=factor_inflate\n",
    "    return data_mask,data_indices,n_data,data_measured_masked,data_var_masked,data_latlon_masked\n",
    "\n",
    "\n",
    "\n",
    "def plot_prior_post(param_f,param_a,param_names_all,i_iter,dir_figs=os.path.join('.','params') ):\n",
    "    if not os.path.exists(dir_figs):\n",
    "        print('Creating folder to store parameter update figures: %s' % (dir_figs) )\n",
    "        os.mkdir(dir_figs)\n",
    "    c = 0\n",
    "    c2 = 0\n",
    "    n_param_max = 16*100 #max 100 plots\n",
    "    n_param = min(len(param_f),n_param_max)\n",
    "    n_figs = np.ceil(n_param/16).astype(int)\n",
    "\n",
    "    for i_ in np.arange(n_param):\n",
    "        if i_ % 16 == 0:\n",
    "            c = 0\n",
    "            fig,axes=plt.subplots(4,4,figsize=(8,7))\n",
    "        row_ = c//4\n",
    "        col_ = c%4\n",
    "\n",
    "        axes[row_,col_].plot(param_f[i_,:],np.zeros(param_f[i_,:].shape),'ko')\n",
    "        axes[row_,col_].plot(param_a[i_,:],np.zeros(param_a[i_,:].shape),'rx')\n",
    "        axes[row_,col_].set_title(param_names_all[i_])\n",
    "        c += 1\n",
    "        if c == 16 or i_ == n_param-1:\n",
    "            fig.suptitle('Iter %i -> %i' %(i_iter,i_iter+1))\n",
    "            fig.tight_layout()\n",
    "            fig.savefig(os.path.join(dir_figs,'params_i%3.3i_%3.3i.png'%(i_iter,c2)) )\n",
    "            c2 += 1\n",
    "\n",
    "            \n",
    "def update_step_ESMDA(param_f,data_f,data_measured,data_var,alpha,i_iter):\n",
    "    print('Calculating KG and performing parameter update...')\n",
    "    assert data_f.shape[0] == len(data_measured)\n",
    "    n_data_ = data_f.shape[0]\n",
    "    n_ensemble = data_f.shape[1]\n",
    "    n_param = param_f.shape[0]\n",
    "    \n",
    "    # 3) construct covariance matrices based on ensemble of parameters and results (data)\n",
    "    # C_D = data_var['SMAP']*sparse.eye(n_data) \n",
    "    C_D = sparse.diags(data_var)\n",
    "    C_MD = np.zeros([n_param,n_data_],dtype=np.float32)\n",
    "    C_DD = np.zeros([n_data_,n_data_],dtype=np.float32)\n",
    "    param_mean = param_f.mean(axis=1)\n",
    "    data_mean = data_f.mean(axis=1)        \n",
    "    param_delta = np.zeros([n_param,n_ensemble])\n",
    "    data_delta = np.zeros([n_data_,n_ensemble])\n",
    "    for i2 in range(n_ensemble):\n",
    "        param_delta[:,i2] = param_f[:,i2] - param_mean\n",
    "        data_delta[:,i2] = data_f[:,i2] - data_mean\n",
    "\n",
    "        C_MD += np.outer(param_delta[:,i2],data_delta[:,i2])\n",
    "        C_DD += np.outer(data_delta[:,i2],data_delta[:,i2])\n",
    "    C_MD /= (n_ensemble - 1)\n",
    "    C_DD /= (n_ensemble - 1)\n",
    "\n",
    "    # Kalman Gain matrix:\n",
    "    KG = np.dot(C_MD,np.linalg.inv(C_DD + alpha[i_iter]*C_D)) \n",
    "\n",
    "    # 4) update the parameters\n",
    "    param_a = np.zeros([n_param, n_ensemble])\n",
    "    mean_mismatch_new = 0\n",
    "    for i_real in range(n_ensemble):\n",
    "\n",
    "        z_d = np.random.normal(0,1,n_data_)\n",
    "        data_perturbed = data_measured + np.sqrt(alpha[i_iter])*np.sqrt(C_D.diagonal())*z_d\n",
    "\n",
    "        mismatch = data_perturbed - data_f[:,i_real]\n",
    "\n",
    "        mean_mismatch_new += np.sum(mismatch**2)\n",
    "\n",
    "        # forecast -> analysis\n",
    "        param_a[:,i_real] = param_f[:,i_real] + np.dot(KG,mismatch)\n",
    "\n",
    "    mean_mismatch_new /= n_ensemble\n",
    "    \n",
    "    return param_a, mean_mismatch_new\n",
    "\n",
    "def update_step_ESMDA_loc(mat_M,mat_D,data_measured,data_var,alpha,i_iter,n_iter,\n",
    "                          param_latlon=None,param_r_loc=None,data_latlon=None,ksi=.99,\n",
    "                          dzeta_global=1.,dir_settings='.',factor_inflate_prior=1.,loc_type='distance',POL_eps=.5):\n",
    "    \"\"\"\n",
    "    Optimized version for many observations\n",
    "    Possibility to include localisation\n",
    "    \n",
    "    Based on appendix of Emerick (2016), j. of Petroleum Science and Engineering \n",
    "    doi.org/10.1016/j.petrol.2016.01.029\n",
    "    \"\"\"\n",
    "\n",
    "    def calculate_alphas(lambda_Wd_,n_iter):\n",
    "        \"\"\"\n",
    "        Based on Rafiee and Reynolds, 2017 (Hankes regularization condition)\n",
    "        Calculate set of inflation factors\n",
    "        \"\"\"\n",
    "        if n_iter == 1:\n",
    "            alphas = [1]\n",
    "        else:\n",
    "            try:\n",
    "                from scipy.optimize import minimize_scalar\n",
    "                def f1(gamma,alpha_1,N_a):\n",
    "                        sum_ = 0\n",
    "                        for i in range(N_a):\n",
    "                            k= i+1\n",
    "                            if ( (gamma**(k-1)) * alpha_1) == 0:\n",
    "                                print(gamma,k,alpha_1)\n",
    "                            sum_ += (1/ ( (gamma**(k-1)) * alpha_1) )\n",
    "\n",
    "                        return (sum_ - 1)**2\n",
    "\n",
    "                rho = .5\n",
    "                alpha_1 = max((rho/(1-rho))*lambda_Wd_.mean()**2,n_iter)\n",
    "\n",
    "                res = minimize_scalar(f1,bounds=(0.001,0.999),bracket=(0.001,0.999),args=(alpha_1,n_iter))\n",
    "                gamma = res.x\n",
    "\n",
    "                alphas = [(gamma**k)*alpha_1 for k in np.arange(n_iter)]\n",
    "                print('Inflation factors (alpha) calculated:',alphas)\n",
    "            except:\n",
    "                print('Inflation factor (alpha) calculation failed, falling back to alpha=n_iter')\n",
    "                alphas = [n_iter for k in np.arange(n_iter)]\n",
    "\n",
    "            assert( np.sum(1/np.array(alphas))-1 < 1e-5)\n",
    "\n",
    "        return alphas\n",
    "\n",
    "    print('Calculating KG and performing parameter update...', flush=True)\n",
    "    print('Using %s localisation' % loc_type)\n",
    "    assert mat_D.shape[0] == len(data_measured)\n",
    "\n",
    "    n_data_ = mat_D.shape[0]\n",
    "    n_ensemble = mat_D.shape[1]\n",
    "    n_param = mat_M.shape[0]\n",
    "\n",
    "    C_D = sparse.diags(data_var)\n",
    "\n",
    "    del_M = (1/np.sqrt(n_ensemble-1))*(mat_M - mat_M.mean(axis=1)[:,np.newaxis])\n",
    "    del_D = (1/np.sqrt(n_ensemble-1))*(mat_D - mat_D.mean(axis=1)[:,np.newaxis])\n",
    "\n",
    "    del_D *= factor_inflate_prior\n",
    "    \n",
    "    S = sparse.diags(C_D.diagonal()**(1/2))\n",
    "    C_Dh = 1.*sparse.eye(n_data_)\n",
    "    Sinv = sparse.diags(1/S.diagonal()) #inverse of diagonal matrix: simply the reciprocal\n",
    "\n",
    "    Ud, lambda_Wd, Vdt = np.linalg.svd(Sinv.dot(del_D), full_matrices=False)\n",
    "    assert(np.all(lambda_Wd[:-1] > lambda_Wd[1:])) #assert that the eigenvalues are sorted\n",
    "\n",
    "    if alpha is None:\n",
    "        print('Calculating inflation factors alpha...', flush=True)\n",
    "        alpha = calculate_alphas(lambda_Wd,n_iter)\n",
    "        print(alpha, flush=True)\n",
    "        change_setting(os.path.join(dir_settings,'settings.py'),'alpha',alpha)\n",
    "        \n",
    "    cumsum_wr = np.cumsum(lambda_Wd) / np.sum(lambda_Wd)\n",
    "    Nr = max(len(lambda_Wd)//2, np.where(cumsum_wr<=ksi)[0][-1]) #take Nr most important singular values, retain at least half the original matrix size just in case\n",
    "\n",
    "    Ur = Ud[:,0:Nr]\n",
    "    Wr = sparse.diags(lambda_Wd[0:Nr])\n",
    "    Vrt = Vdt[0:Nr,0:Nr]\n",
    "    Ir = sparse.eye(Nr)\n",
    "    Wrinv = sparse.diags(1/Wr.diagonal()) \n",
    "\n",
    "    mat_R = alpha[i_iter]*(Wrinv @ Ur.T @ C_Dh @ Ur @ Wrinv)\n",
    "\n",
    "    Zr, lambda_Hr, Zrt = np.linalg.svd(mat_R, full_matrices=False)\n",
    "    Hr = sparse.diags(lambda_Hr)\n",
    "\n",
    "    mat_X = Sinv @ Ur @ Wrinv @ Zr\n",
    "    mat_L = Ir + Hr\n",
    "    mat_Linv = sparse.diags(1/mat_L.diagonal()) \n",
    "\n",
    "    mat_X1 = mat_Linv @ mat_X.T\n",
    "    mat_X2 = del_D.T @ mat_X\n",
    "    mat_X3 = mat_X2 @ mat_X1\n",
    "\n",
    "    # perturb observations, at the same time calculate the mismatch of the current forecast\n",
    "    mat_Dobs = np.zeros(mat_D.shape)\n",
    "    mean_mismatch_new = 0\n",
    "    for i_real in range(n_ensemble):\n",
    "        z_d = np.random.normal(0,1,n_data_)\n",
    "        mat_Dobs[:,i_real] = data_measured + np.sqrt(alpha[i_iter])*np.sqrt(C_D.diagonal())*z_d\n",
    "        mismatch = mat_Dobs[:,i_real] - mat_D[:,i_real]\n",
    "        mean_mismatch_new += np.sum(mismatch**2)\n",
    "    mean_mismatch_new /= n_ensemble\n",
    "    \n",
    "    sum_d_localized = 0\n",
    "    sum_d_global = 0\n",
    "    n_param_localized_tot = 0\n",
    "    # calculate updated (analysis) parameters\n",
    "    \n",
    "    # used for POL localisation:\n",
    "    c_ii = np.var( (mat_M - mat_M.mean(axis=1)[:,np.newaxis]), axis=1, ddof=1) #(n_param,) -> estimate of C_M\n",
    "    c_jj = np.var( (mat_D - mat_D.mean(axis=1)[:,np.newaxis]), axis=1, ddof=1) #(n_data,) -> estimate of C_D\n",
    "\n",
    "    param_a = np.zeros(mat_M.shape)\n",
    "    for i in range(n_param):\n",
    "        \n",
    "        # first localisation option: distance based, by using haversine distance & GC function\n",
    "        if loc_type == 'distance':    \n",
    "            if np.isnan(param_r_loc[i]):\n",
    "                rho_i = dzeta_global*np.ones(n_data_) #no localisation\n",
    "            else:\n",
    "                r_loc = param_r_loc[i]\n",
    "                # localisation using the Gaspari-Cohn localisation function:\n",
    "                rho_i = GC(haversine_distance(param_latlon[i,:],data_latlon),r_loc)\n",
    "        # second option: pseudo optimal localization\n",
    "        # see e.g. Lacerda et al. (2019), Furrer et al. (2007)\n",
    "        elif loc_type == 'POL':\n",
    "            ci = del_M[i,:]@(del_D[:,:].T)\n",
    "            rho_i = ci**2 / (ci**2 + (ci**2+(c_ii[i]*c_jj)/n_ensemble) )\n",
    "            mask_zero = np.abs(ci) < POL_eps*np.sqrt(c_ii[i]*c_jj)\n",
    "            rho_i[mask_zero] = 0\n",
    "            \n",
    "        else:\n",
    "            print('Warning!! Localisation method unknown. Set to POL or distance')\n",
    "            rho_i = np.ones(n_data_)\n",
    "\n",
    "            \n",
    "        K_i = del_M[i,:]@mat_X3\n",
    "        K_rho_i = K_i * rho_i\n",
    "        mat_X4 = K_rho_i @ (mat_Dobs - mat_D)\n",
    "        param_a[i,:] = mat_M[i,:] + mat_X4\n",
    " \n",
    "    return param_a, mean_mismatch_new, alpha\n",
    "\n",
    "\n",
    "def GC(r, c):\n",
    "    #Gaspari-Cohn localization function\n",
    "    abs_r = np.abs(r)\n",
    "    if np.isnan(c):\n",
    "        result = np.ones_like(abs_r, dtype=float)\n",
    "    else:\n",
    "        condition1 = (0 <= abs_r) & (abs_r <= c)\n",
    "        condition2 = (c <= abs_r) & (abs_r <= 2 * c)\n",
    "\n",
    "        result = np.zeros_like(abs_r, dtype=float)\n",
    "\n",
    "        result[condition1] = -1/4 * (abs_r[condition1] / c) ** 5 + 1/2 * (abs_r[condition1] / c) ** 4 + 5/8 * (abs_r[condition1] / c) ** 3 - \\\n",
    "                            5/3 * (abs_r[condition1] / c) ** 2 + 1\n",
    "        result[condition2] = 1/12 * (abs_r[condition2] / c) ** 5 - 1/2 * (abs_r[condition2] / c) ** 4 + 5/8 * (abs_r[condition2] / c) ** 3 + \\\n",
    "                            5/3 * (abs_r[condition2] / c) ** 2 - 5 * (abs_r[condition2] / c) + 4 - 2/3 * (c / abs_r[condition2])\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "\n",
    "# which data to assimilate: \n",
    "data_names = settings_DA['data_names']\n",
    "# If uncertainties are assumed constant, prescribe:\n",
    "# data_var = {'SMAP':0.04**2,\n",
    "#             'FLX':None}\n",
    "data_var = settings_DA['data_var']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8840707a-0fed-458a-a1e4-4c6ab185acb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "folder_results = '/p/scratch/cjibg36/jibg3674/CLM5_DA/small_test_ap'\n",
    "if folder_results not in sys.path:\n",
    "    sys.path.insert(0,os.path.join(folder_results,'settings'))\n",
    "import settings\n",
    "importlib.reload(settings)\n",
    "from settings import settings_run,settings_clm,settings_pfl,settings_sbatch,settings_DA,settings_gen,date_results_binned,freq_output,date_range_noleap\n",
    "\n",
    "settings_run['remove_hist_files'] = ['h1','h2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "194dfd3c-ba4e-455d-9702-1a6490241410",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_members_SMAP = 0 #set to int (iteration for which to plot members), or to False/True\n",
    "plot_members_FLX = True\n",
    "\n",
    "# which data to assimilate: \n",
    "data_names = settings_DA['data_names']\n",
    "data_var = {'SMAP':0.04**2,\n",
    "            'FLX':None}\n",
    "\n",
    "data_mask = {'SMAP':None, #initialize dict\n",
    "             'FLX':None}\n",
    "\n",
    "\n",
    "# prescribe_alpha = settings_DA['prescribe_alpha']\n",
    "alpha = settings_DA['alpha']\n",
    "factor_inflate = settings_DA['factor_inflate']\n",
    "factor_inflate_prior = settings_DA['factor_inflate_prior']\n",
    "ksi=settings_DA['cutoff_svd']\n",
    "\n",
    "### Unpack some of the settings into variables\n",
    "# Functions that are run to initialize the parameters to be assimilated. \n",
    "# E.g. for spatial parameter fields, initialize the static fields (x,y,z) locations and the prior/uncertainty estimates\n",
    "param_setup = settings_DA['param_setup'] \n",
    "# Functions that are run to generate realizations of parameters/state variables\n",
    "param_gen   = settings_DA['param_gen']\n",
    "# Define parameter names; parameters values are stored in (%s.param.npy % param_name) files\n",
    "param_names = settings_DA['param_names']\n",
    "\n",
    "# possibility to only select a limited amount of observations using masks\n",
    "data_nselect = settings_DA['n_data_max']\n",
    "\n",
    "n_parallel = settings_DA['n_parallel']\n",
    "n_parallel_setup = settings_DA['n_parallel_setup']\n",
    "n_ensemble = settings_DA['n_ensemble']\n",
    "n_iter = settings_DA['n_iter']\n",
    "dir_setup = settings_run['dir_setup']\n",
    "dir_template = settings_run['dir_template']\n",
    "atm_perb = settings_run['atm_perb']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4148fbf5-45d9-4adc-b0c0-1cba6a45bd27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/p/scratch/cjibg36/jibg3674/CLM5_DA/small_test_ap'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "057f81e7-4b59-473a-ac28-f299dc91627b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing simulation in /p/scratch/cjibg36/jibg3674/CLM5_DA/small_test_ap\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    " 1) Copy the folder template to the setup location if the destination does not exist\n",
    "'''\n",
    "if not os.path.exists(dir_setup):\n",
    "    print('Copying folder template from %s to %s' % (dir_template,dir_setup) )\n",
    "    shutil.copytree(dir_template,dir_setup)\n",
    "else:\n",
    "    print('Continuing simulation in %s' % dir_setup)\n",
    "# os.chdir(dir_setup)\n",
    "\n",
    "# copy settings file for later use\n",
    "dir_settings = os.path.join(settings_run['dir_setup'],'settings')\n",
    "if not os.path.exists(dir_settings):\n",
    "    os.mkdir(dir_settings)\n",
    "    shutil.copy('/p/project1/cjibg36/jibg3674/eCLM_PyDA/TSMP_DA/DA/settings.py',dir_settings)\n",
    "\n",
    "dir_figs = os.path.join(dir_setup,'figures')\n",
    "settings_run['dir_figs'] = dir_figs\n",
    "if not os.path.exists(dir_figs):\n",
    "    print('Creating folder to store DA information: %s' % (dir_figs) )\n",
    "    os.mkdir(dir_figs)\n",
    "\n",
    "dir_DA = os.path.join(dir_setup,'input_DA')\n",
    "settings_run['dir_DA'] = dir_DA\n",
    "if not os.path.exists(dir_DA):\n",
    "    print('Creating folder to store DA information: %s' % (dir_DA) )\n",
    "    os.mkdir(dir_DA)\n",
    "\n",
    "    # setup parameters: prior/uncertainties, + static properties, lon/lat locations based on the settings if necessary\n",
    "    for fn in param_setup:\n",
    "        fn(settings_gen,settings_run)\n",
    "\n",
    "# Read parameter length and put in dictionary here\n",
    "for param_ in param_names:\n",
    "    settings_gen['param_length'][param_] = np.load(os.path.join(dir_DA,'%s.param.000.000.prior.npy' % param_) ).shape[0]\n",
    "\n",
    "#%% ----------- DA loop -----------\n",
    "\n",
    "\n",
    "#%% ----------- date loop -----------    \n",
    "# this comes in the date loop, e.g. perform the smoother over a period over 1 year:\n",
    "i_date = 0\n",
    "date_results_iter = date_results_binned[i_date].copy()\n",
    "date_start_sim = date_results_binned[i_date][0][0]#datetime(2019,1,2,12,0,0)\n",
    "date_end_sim = date_results_binned[i_date][-1][-1]#datetime(2019,12,31,12,0,0)\n",
    "\n",
    "# add spinup if necessary:\n",
    "if settings_run['ndays_spinup'] is not None:\n",
    "    date_results_iter.insert(0,list(date_range_noleap(date_start_sim-timedelta(days=settings_run['ndays_spinup']),date_start_sim,periods=2)))\n",
    "\n",
    "\n",
    "str_date = str(date_start_sim.date()).replace('-','') + '-' + str(date_end_sim.date()).replace('-','')\n",
    "dir_date = os.path.join(dir_setup,str_date)\n",
    "if not os.path.exists(dir_date):\n",
    "    print('Creating folder for dates %s: %s' % (str_date,dir_date) )\n",
    "    os.mkdir(dir_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "38050a5e-52e0-4522-b905-bdaea63fda6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mismatch_iter = [0]\n",
    "i_iter = 0\n",
    "init = True\n",
    "\n",
    "str_iter = 'i%3.3i' % i_iter\n",
    "dir_iter = os.path.join(dir_date,str_iter)\n",
    "if os.path.exists(os.path.join(dir_DA,'%s.param.000.%3.3i.000.npy'%(param_names[0],i_iter+1)) ): #check if the next iteration parameter files already exist\n",
    "    print('Iteration %i seems to have finished succesfully, continuing with the next iteration...' % i_iter)\n",
    "else:\n",
    "    if not os.path.exists(dir_iter):\n",
    "        print('Creating folder for iteration %i: %s' % (i_iter,dir_iter) )\n",
    "        os.mkdir(dir_iter)\n",
    "        \n",
    "settings_run['dir_iter'] = dir_iter\n",
    "settings_gen['i_date'] = i_date\n",
    "settings_gen['i_iter'] = i_iter\n",
    "settings_gen['param_gen'] = param_gen\n",
    "settings_gen['param_names'] = param_names\n",
    "settings_gen['param_r_loc'] = settings_DA['param_r_loc']\n",
    "\n",
    "for i_real in np.arange(0,n_ensemble+1):\n",
    "    realize_parameters(i_real,settings_gen,settings_run,init=init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0aae7b23-5b12-4d40-b513-f546b3fbeae7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_ensemble: 3\n",
      "Amount of parameters to assimilate: 1294\n"
     ]
    }
   ],
   "source": [
    "print('n_ensemble: %i' % n_ensemble, flush=True)\n",
    "# Aggregrate all parameter values into param_f\n",
    "param_f,param_names_all,param_latlon,param_r_loc = read_parameters(n_ensemble,settings_gen,settings_run)\n",
    "n_param = len(param_f)\n",
    "print('Amount of parameters to assimilate: %i' % n_param, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "57e49ee9-5dd0-4106-a604-82eef40a1a96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import run_realization_v2\n",
    "importlib.reload(run_realization_v2)\n",
    "from run_realization_v2 import setup_submit_wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0a1a30d3-68b6-4a4e-97f6-99e61a5ec33e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restarting run from /p/project/cjibg36/jibg3674/shared_DA/EU11.clm2.r.2019-01-01-00000.nc and FalseRestarting run from /p/project/cjibg36/jibg3674/shared_DA/EU11.clm2.r.2019-01-01-00000.nc and False\n",
      "Restarting run from /p/project/cjibg36/jibg3674/shared_DA/EU11.clm2.r.2019-01-01-00000.nc and FalseRestarting run from /p/project/cjibg36/jibg3674/shared_DA/EU11.clm2.r.2019-01-01-00000.nc and False\n",
      "\n",
      "\n",
      "Preparing simulation in /p/scratch/cjibg36/jibg3674/CLM5_DA/small_test_ap/20190501-20190531/i000/R001/run_20190302-20190501Preparing simulation in /p/scratch/cjibg36/jibg3674/CLM5_DA/small_test_ap/20190501-20190531/i000/R002/run_20190302-20190501Preparing simulation in /p/scratch/cjibg36/jibg3674/CLM5_DA/small_test_ap/20190501-20190531/i000/R000/run_20190302-20190501Preparing simulation in /p/scratch/cjibg36/jibg3674/CLM5_DA/small_test_ap/20190501-20190531/i000/R003/run_20190302-20190501\n",
      "\n",
      "\n",
      "\n",
      "Copy binaries from /p/project1/cjibg36/jibg3674/eCLM_PyDA/eCLM/eclm/bin/\n",
      "Copy binaries from /p/project1/cjibg36/jibg3674/eCLM_PyDA/eCLM/eclm/bin/\n",
      "Copy binaries from /p/project1/cjibg36/jibg3674/eCLM_PyDA/eCLM/eclm/bin/Copy binaries from /p/project1/cjibg36/jibg3674/eCLM_PyDA/eCLM/eclm/bin/\n",
      "\n",
      "Checking the real 3 for atmospheric perturbation  \n",
      "\n",
      "Checking the real 1 for atmospheric perturbation  \n",
      "\n",
      "Checking the real 2 for atmospheric perturbation  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[01;33mThis stage is deprecated. Please consider moving to a new stage (2024\n",
      "or newer)\u001b[0m\n",
      "\n",
      "\n",
      "  \u001b[01;33mThis stage is deprecated. Please consider moving to a new stage (2024\n",
      "or newer)\u001b[0m\n",
      "\n",
      "\n",
      "  \u001b[01;33mThis stage is deprecated. Please consider moving to a new stage (2024\n",
      "or newer)\u001b[0m\n",
      "\n",
      "\n",
      "  \u001b[01;33mThis stage is deprecated. Please consider moving to a new stage (2024\n",
      "or newer)\u001b[0m\n",
      "\n",
      "\n",
      "The following have been reloaded with a version change:\n",
      "  1) HDF5/1.12.2 => HDF5/1.12.2-serial\n",
      "\n",
      "\n",
      "The following have been reloaded with a version change:\n",
      "  1) HDF5/1.12.2 => HDF5/1.12.2-serial\n",
      "\n",
      "\n",
      "The following have been reloaded with a version change:\n",
      "  1) HDF5/1.12.2 => HDF5/1.12.2-serial\n",
      "\n",
      "\n",
      "The following have been reloaded with a version change:\n",
      "  1) HDF5/1.12.2 => HDF5/1.12.2-serial\n",
      "\n",
      "\n",
      "The following have been reloaded with a version change:\n",
      "  1) HDF5/1.12.2-serial => HDF5/1.12.2\n",
      "\n",
      "\n",
      "The following have been reloaded with a version change:\n",
      "  1) HDF5/1.12.2-serial => HDF5/1.12.2\n",
      "\n",
      "\n",
      "The following have been reloaded with a version change:\n",
      "  1) HDF5/1.12.2-serial => HDF5/1.12.2\n",
      "\n",
      "\n",
      "The following have been reloaded with a version change:\n",
      "  1) HDF5/1.12.2-serial => HDF5/1.12.2\n",
      "\n",
      "\n",
      "Currently Loaded Modules:\n",
      "  1) Stages/2023            (S)  33) netCDF/4.9.0\n",
      "  2) GCCcore/.11.3.0        (H)  34) netCDF-Fortran/4.6.0\n",
      "  3) zlib/.1.2.12           (H)  35) PnetCDF/1.12.3\n",
      "  4) binutils/.2.38         (H)  36) cURL/7.83.0\n",
      "  5) Intel/2022.1.0              37) Szip/.2.1.1          (H)\n",
      "  6) numactl/2.0.15              38) ncurses/.6.3         (H)\n",
      "  7) nvidia-driver/.default (H)  39) libreadline/.8.1.2   (H)\n",
      "  8) CUDA/11.7              (g)  40) SQLite/.3.38.3       (H)\n",
      "  9) UCX-settings/RC             41) GMP/6.2.1\n",
      " 10) UCX/default            (g)  42) libffi/.3.4.2        (H)\n",
      " 11) pscom/.5.6-default     (H)  43) Python/3.10.4\n",
      " 12) XZ/.5.2.5              (H)  44) expat/.2.4.8         (H)\n",
      " 13) libxml2/.2.9.13        (H)  45) UDUNITS/.2.2.28      (H)\n",
      " 14) MPI-settings/UCX            46) Java/11.0.16\n",
      " 15) ParaStationMPI/5.7.0-1 (g)  47) ANTLR/.2.7.7         (H)\n",
      " 16) imkl/2022.1.0               48) libtirpc/.1.3.2      (H)\n",
      " 17) imkl-FFTW/2022.1.0          49) PCRE/.8.45           (H)\n",
      " 18) Hypre/2.27.0-cpu            50) util-linux/.2.38     (H)\n",
      " 19) Silo/4.11                   51) libdap/.3.20.11      (H)\n",
      " 20) Tcl/8.6.12                  52) GSL/2.7\n",
      " 21) OpenSSL/1.1                 53) NCO/5.1.3\n",
      " 22) gzip/.1.12             (H)  54) libarchive/3.6.1\n",
      " 23) lz4/.1.9.3             (H)  55) CMake/3.23.1\n",
      " 24) zstd/.1.5.2            (H)  56) gettext/.0.21        (H)\n",
      " 25) bzip2/.1.0.8           (H)  57) DB/.18.1.40          (H)\n",
      " 26) JasPer/.2.0.33         (H)  58) XML-LibXML/.2.0207   (H)\n",
      " 27) NASM/.2.15.05          (H)  59) DB_File/.1.858       (H)\n",
      " 28) libjpeg-turbo/.2.1.3   (H)  60) BioPerl/1.7.8\n",
      " 29) libpng/.1.6.37         (H)  61) Perl-JSC-extra/2022a\n",
      " 30) libaec/1.0.6                62) Perl/5.34.1\n",
      " 31) ecCodes/2.27.0              63) git/2.36.0-nodocs\n",
      " 32) HDF5/1.12.2\n",
      "\n",
      "  Where:\n",
      "   H:  Hidden Module\n",
      "   S:  Module is Sticky, requires --force to unload or purge\n",
      "   g:  Built with GPU support\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Currently Loaded Modules:\n",
      "  1) Stages/2023            (S)  33) netCDF/4.9.0\n",
      "  2) GCCcore/.11.3.0        (H)  34) netCDF-Fortran/4.6.0\n",
      "  3) zlib/.1.2.12           (H)  35) PnetCDF/1.12.3\n",
      "  4) binutils/.2.38         (H)  36) cURL/7.83.0\n",
      "  5) Intel/2022.1.0              37) Szip/.2.1.1          (H)\n",
      "  6) numactl/2.0.15              38) ncurses/.6.3         (H)\n",
      "  7) nvidia-driver/.default (H)  39) libreadline/.8.1.2   (H)\n",
      "  8) CUDA/11.7              (g)  40) SQLite/.3.38.3       (H)\n",
      "  9) UCX-settings/RC             41) GMP/6.2.1\n",
      " 10) UCX/default            (g)  42) libffi/.3.4.2        (H)\n",
      " 11) pscom/.5.6-default     (H)  43) Python/3.10.4\n",
      " 12) XZ/.5.2.5              (H)  44) expat/.2.4.8         (H)\n",
      " 13) libxml2/.2.9.13        (H)  45) UDUNITS/.2.2.28      (H)\n",
      " 14) MPI-settings/UCX            46) Java/11.0.16\n",
      " 15) ParaStationMPI/5.7.0-1 (g)  47) ANTLR/.2.7.7         (H)\n",
      " 16) imkl/2022.1.0               48) libtirpc/.1.3.2      (H)\n",
      " 17) imkl-FFTW/2022.1.0          49) PCRE/.8.45           (H)\n",
      " 18) Hypre/2.27.0-cpu            50) util-linux/.2.38     (H)\n",
      " 19) Silo/4.11                   51) libdap/.3.20.11      (H)\n",
      " 20) Tcl/8.6.12                  52) GSL/2.7\n",
      " 21) OpenSSL/1.1                 53) NCO/5.1.3\n",
      " 22) gzip/.1.12             (H)  54) libarchive/3.6.1\n",
      " 23) lz4/.1.9.3             (H)  55) CMake/3.23.1\n",
      " 24) zstd/.1.5.2            (H)  56) gettext/.0.21        (H)\n",
      " 25) bzip2/.1.0.8           (H)  57) DB/.18.1.40          (H)\n",
      " 26) JasPer/.2.0.33         (H)  58) XML-LibXML/.2.0207   (H)\n",
      " 27) NASM/.2.15.05          (H)  59) DB_File/.1.858       (H)\n",
      " 28) libjpeg-turbo/.2.1.3   (H)  60) BioPerl/1.7.8\n",
      " 29) libpng/.1.6.37         (H)  61) Perl-JSC-extra/2022a\n",
      " 30) libaec/1.0.6                62) Perl/5.34.1\n",
      " 31) ecCodes/2.27.0              63) git/2.36.0-nodocs\n",
      " 32) HDF5/1.12.2\n",
      "\n",
      "  Where:\n",
      "   H:  Hidden Module\n",
      "   S:  Module is Sticky, requires --force to unload or purge\n",
      "   g:  Built with GPU support\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Currently Loaded Modules:\n",
      "  1) Stages/2023            (S)  33) netCDF/4.9.0\n",
      "  2) GCCcore/.11.3.0        (H)  34) netCDF-Fortran/4.6.0\n",
      "  3) zlib/.1.2.12           (H)  35) PnetCDF/1.12.3\n",
      "  4) binutils/.2.38         (H)  36) cURL/7.83.0\n",
      "  5) Intel/2022.1.0              37) Szip/.2.1.1          (H)\n",
      "  6) numactl/2.0.15              38) ncurses/.6.3         (H)\n",
      "  7) nvidia-driver/.default (H)  39) libreadline/.8.1.2   (H)\n",
      "  8) CUDA/11.7              (g)  40) SQLite/.3.38.3       (H)\n",
      "  9) UCX-settings/RC             41) GMP/6.2.1\n",
      " 10) UCX/default            (g)  42) libffi/.3.4.2        (H)\n",
      " 11) pscom/.5.6-default     (H)  43) Python/3.10.4\n",
      " 12) XZ/.5.2.5              (H)  44) expat/.2.4.8         (H)\n",
      " 13) libxml2/.2.9.13        (H)  45) UDUNITS/.2.2.28      (H)\n",
      " 14) MPI-settings/UCX            46) Java/11.0.16\n",
      " 15) ParaStationMPI/5.7.0-1 (g)  47) ANTLR/.2.7.7         (H)\n",
      " 16) imkl/2022.1.0               48) libtirpc/.1.3.2      (H)\n",
      " 17) imkl-FFTW/2022.1.0          49) PCRE/.8.45           (H)\n",
      " 18) Hypre/2.27.0-cpu            50) util-linux/.2.38     (H)\n",
      " 19) Silo/4.11                   51) libdap/.3.20.11      (H)\n",
      " 20) Tcl/8.6.12                  52) GSL/2.7\n",
      " 21) OpenSSL/1.1                 53) NCO/5.1.3\n",
      " 22) gzip/.1.12             (H)  54) libarchive/3.6.1\n",
      " 23) lz4/.1.9.3             (H)  55) CMake/3.23.1\n",
      " 24) zstd/.1.5.2            (H)  56) gettext/.0.21        (H)\n",
      " 25) bzip2/.1.0.8           (H)  57) DB/.18.1.40          (H)\n",
      " 26) JasPer/.2.0.33         (H)  58) XML-LibXML/.2.0207   (H)\n",
      " 27) NASM/.2.15.05          (H)  59) DB_File/.1.858       (H)\n",
      " 28) libjpeg-turbo/.2.1.3   (H)  60) BioPerl/1.7.8\n",
      " 29) libpng/.1.6.37         (H)  61) Perl-JSC-extra/2022a\n",
      " 30) libaec/1.0.6                62) Perl/5.34.1\n",
      " 31) ecCodes/2.27.0              63) git/2.36.0-nodocs\n",
      " 32) HDF5/1.12.2\n",
      "\n",
      "  Where:\n",
      "   H:  Hidden Module\n",
      "   S:  Module is Sticky, requires --force to unload or purge\n",
      "   g:  Built with GPU support\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Currently Loaded Modules:\n",
      "  1) Stages/2023            (S)  33) netCDF/4.9.0\n",
      "  2) GCCcore/.11.3.0        (H)  34) netCDF-Fortran/4.6.0\n",
      "  3) zlib/.1.2.12           (H)  35) PnetCDF/1.12.3\n",
      "  4) binutils/.2.38         (H)  36) cURL/7.83.0\n",
      "  5) Intel/2022.1.0              37) Szip/.2.1.1          (H)\n",
      "  6) numactl/2.0.15              38) ncurses/.6.3         (H)\n",
      "  7) nvidia-driver/.default (H)  39) libreadline/.8.1.2   (H)\n",
      "  8) CUDA/11.7              (g)  40) SQLite/.3.38.3       (H)\n",
      "  9) UCX-settings/RC             41) GMP/6.2.1\n",
      " 10) UCX/default            (g)  42) libffi/.3.4.2        (H)\n",
      " 11) pscom/.5.6-default     (H)  43) Python/3.10.4\n",
      " 12) XZ/.5.2.5              (H)  44) expat/.2.4.8         (H)\n",
      " 13) libxml2/.2.9.13        (H)  45) UDUNITS/.2.2.28      (H)\n",
      " 14) MPI-settings/UCX            46) Java/11.0.16\n",
      " 15) ParaStationMPI/5.7.0-1 (g)  47) ANTLR/.2.7.7         (H)\n",
      " 16) imkl/2022.1.0               48) libtirpc/.1.3.2      (H)\n",
      " 17) imkl-FFTW/2022.1.0          49) PCRE/.8.45           (H)\n",
      " 18) Hypre/2.27.0-cpu            50) util-linux/.2.38     (H)\n",
      " 19) Silo/4.11                   51) libdap/.3.20.11      (H)\n",
      " 20) Tcl/8.6.12                  52) GSL/2.7\n",
      " 21) OpenSSL/1.1                 53) NCO/5.1.3\n",
      " 22) gzip/.1.12             (H)  54) libarchive/3.6.1\n",
      " 23) lz4/.1.9.3             (H)  55) CMake/3.23.1\n",
      " 24) zstd/.1.5.2            (H)  56) gettext/.0.21        (H)\n",
      " 25) bzip2/.1.0.8           (H)  57) DB/.18.1.40          (H)\n",
      " 26) JasPer/.2.0.33         (H)  58) XML-LibXML/.2.0207   (H)\n",
      " 27) NASM/.2.15.05          (H)  59) DB_File/.1.858       (H)\n",
      " 28) libjpeg-turbo/.2.1.3   (H)  60) BioPerl/1.7.8\n",
      " 29) libpng/.1.6.37         (H)  61) Perl-JSC-extra/2022a\n",
      " 30) libaec/1.0.6                62) Perl/5.34.1\n",
      " 31) ecCodes/2.27.0              63) git/2.36.0-nodocs\n",
      " 32) HDF5/1.12.2\n",
      "\n",
      "  Where:\n",
      "   H:  Hidden Module\n",
      "   S:  Module is Sticky, requires --force to unload or purge\n",
      "   g:  Built with GPU support\n",
      "\n",
      " \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still running (['20190501-20190531', 'i000', 'R003'])...\n",
      "Submitted batch job 10183192\n",
      "Still running (['20190501-20190531', 'i000', 'R000'])...\n",
      "Still running (['20190501-20190531', 'i000', 'R001'])...\n",
      "Submitted batch job 10183193\n",
      "Submitted batch job 10183194\n",
      "Still running (['20190501-20190531', 'i000', 'R002'])...\n",
      "Submitted batch job 10183195\n",
      "Still running (['20190501-20190531', 'i000', 'R003'])...\n",
      "Still running (['20190501-20190531', 'i000', 'R000'])...\n",
      "Still running (['20190501-20190531', 'i000', 'R001'])...\n",
      "Still running (['20190501-20190531', 'i000', 'R002'])...\n",
      "Still running (['20190501-20190531', 'i000', 'R003'])...\n",
      "Still running (['20190501-20190531', 'i000', 'R000'])...\n",
      "Still running (['20190501-20190531', 'i000', 'R001'])...\n",
      "Still running (['20190501-20190531', 'i000', 'R002'])...\n",
      "Still running (['20190501-20190531', 'i000', 'R003'])...\n",
      "Still running (['20190501-20190531', 'i000', 'R000'])...\n",
      "Still running (['20190501-20190531', 'i000', 'R001'])...\n",
      "/p/scratch/cjibg36/jibg3674/CLM5_DA/small_test_ap/20190501-20190531/i000/R002/run_20190302-20190501\n",
      "[]\n",
      "An exception occurred: list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/p/project1/cjibg36/jibg3674/eCLM_PyDA/TSMP_DA/DA/run_realization_v2.py\", line 637, in setup_submit_wait\n",
      "    print(files_clm_restart[-1].split('.'))\n",
      "IndexError: list index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/p/scratch/cjibg36/jibg3674/CLM5_DA/small_test_ap/20190501-20190531/i000/R003/run_20190302-20190501\n",
      "['/p/scratch/cjibg36/jibg3674/CLM5_DA/small_test_ap/20190501-20190531/i000/R003/run_20190302-20190501/EU11.clm2.r.2019-05-01-00000.nc']\n",
      "['/p/scratch/cjibg36/jibg3674/CLM5_DA/small_test_ap/20190501-20190531/i000/R003/run_20190302-20190501/EU11', 'clm2', 'r', '2019-05-01-00000', 'nc']\n",
      "Restarting CLM from /p/scratch/cjibg36/jibg3674/CLM5_DA/small_test_ap/20190501-20190531/i000/R003/run_20190302-20190501/EU11.clm2.r.2019-05-01-00000.nc\n",
      "Preparing simulation in /p/scratch/cjibg36/jibg3674/CLM5_DA/small_test_ap/20190501-20190531/i000/R003/run_20190501-20190531\n",
      "Copy binaries from /p/project1/cjibg36/jibg3674/eCLM_PyDA/eCLM/eclm/bin/\n",
      "/p/scratch/cjibg36/jibg3674/CLM5_DA/small_test_ap/20190501-20190531/i000/R000/run_20190302-20190501\n",
      "['/p/scratch/cjibg36/jibg3674/CLM5_DA/small_test_ap/20190501-20190531/i000/R000/run_20190302-20190501/EU11.clm2.r.2019-05-01-00000.nc']\n",
      "['/p/scratch/cjibg36/jibg3674/CLM5_DA/small_test_ap/20190501-20190531/i000/R000/run_20190302-20190501/EU11', 'clm2', 'r', '2019-05-01-00000', 'nc']\n",
      "Restarting CLM from /p/scratch/cjibg36/jibg3674/CLM5_DA/small_test_ap/20190501-20190531/i000/R000/run_20190302-20190501/EU11.clm2.r.2019-05-01-00000.nc\n",
      "Preparing simulation in /p/scratch/cjibg36/jibg3674/CLM5_DA/small_test_ap/20190501-20190531/i000/R000/run_20190501-20190531\n",
      "Checking the real 3 for atmospheric perturbation  \n",
      "\n",
      "Copy binaries from /p/project1/cjibg36/jibg3674/eCLM_PyDA/eCLM/eclm/bin/\n",
      "/p/scratch/cjibg36/jibg3674/CLM5_DA/small_test_ap/20190501-20190531/i000/R001/run_20190302-20190501\n",
      "['/p/scratch/cjibg36/jibg3674/CLM5_DA/small_test_ap/20190501-20190531/i000/R001/run_20190302-20190501/EU11.clm2.r.2019-05-01-00000.nc']\n",
      "['/p/scratch/cjibg36/jibg3674/CLM5_DA/small_test_ap/20190501-20190531/i000/R001/run_20190302-20190501/EU11', 'clm2', 'r', '2019-05-01-00000', 'nc']\n",
      "Restarting CLM from /p/scratch/cjibg36/jibg3674/CLM5_DA/small_test_ap/20190501-20190531/i000/R001/run_20190302-20190501/EU11.clm2.r.2019-05-01-00000.nc\n",
      "Preparing simulation in /p/scratch/cjibg36/jibg3674/CLM5_DA/small_test_ap/20190501-20190531/i000/R001/run_20190501-20190531\n",
      "Copy binaries from /p/project1/cjibg36/jibg3674/eCLM_PyDA/eCLM/eclm/bin/\n",
      "Checking the real 1 for atmospheric perturbation  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[01;33mThis stage is deprecated. Please consider moving to a new stage (2024\n",
      "or newer)\u001b[0m\n",
      "\n",
      "\n",
      "  \u001b[01;33mThis stage is deprecated. Please consider moving to a new stage (2024\n",
      "or newer)\u001b[0m\n",
      "\n",
      "\n",
      "  \u001b[01;33mThis stage is deprecated. Please consider moving to a new stage (2024\n",
      "or newer)\u001b[0m\n",
      "\n",
      "\n",
      "The following have been reloaded with a version change:\n",
      "  1) HDF5/1.12.2 => HDF5/1.12.2-serial\n",
      "\n",
      "\n",
      "The following have been reloaded with a version change:\n",
      "  1) HDF5/1.12.2 => HDF5/1.12.2-serial\n",
      "\n",
      "\n",
      "The following have been reloaded with a version change:\n",
      "  1) HDF5/1.12.2 => HDF5/1.12.2-serial\n",
      "\n",
      "\n",
      "The following have been reloaded with a version change:\n",
      "  1) HDF5/1.12.2-serial => HDF5/1.12.2\n",
      "\n",
      "\n",
      "The following have been reloaded with a version change:\n",
      "  1) HDF5/1.12.2-serial => HDF5/1.12.2\n",
      "\n",
      "\n",
      "The following have been reloaded with a version change:\n",
      "  1) HDF5/1.12.2-serial => HDF5/1.12.2\n",
      "\n",
      "\n",
      "Currently Loaded Modules:\n",
      "  1) Stages/2023            (S)  33) netCDF/4.9.0\n",
      "  2) GCCcore/.11.3.0        (H)  34) netCDF-Fortran/4.6.0\n",
      "  3) zlib/.1.2.12           (H)  35) PnetCDF/1.12.3\n",
      "  4) binutils/.2.38         (H)  36) cURL/7.83.0\n",
      "  5) Intel/2022.1.0              37) Szip/.2.1.1          (H)\n",
      "  6) numactl/2.0.15              38) ncurses/.6.3         (H)\n",
      "  7) nvidia-driver/.default (H)  39) libreadline/.8.1.2   (H)\n",
      "  8) CUDA/11.7              (g)  40) SQLite/.3.38.3       (H)\n",
      "  9) UCX-settings/RC             41) GMP/6.2.1\n",
      " 10) UCX/default            (g)  42) libffi/.3.4.2        (H)\n",
      " 11) pscom/.5.6-default     (H)  43) Python/3.10.4\n",
      " 12) XZ/.5.2.5              (H)  44) expat/.2.4.8         (H)\n",
      " 13) libxml2/.2.9.13        (H)  45) UDUNITS/.2.2.28      (H)\n",
      " 14) MPI-settings/UCX            46) Java/11.0.16\n",
      " 15) ParaStationMPI/5.7.0-1 (g)  47) ANTLR/.2.7.7         (H)\n",
      " 16) imkl/2022.1.0               48) libtirpc/.1.3.2      (H)\n",
      " 17) imkl-FFTW/2022.1.0          49) PCRE/.8.45           (H)\n",
      " 18) Hypre/2.27.0-cpu            50) util-linux/.2.38     (H)\n",
      " 19) Silo/4.11                   51) libdap/.3.20.11      (H)\n",
      " 20) Tcl/8.6.12                  52) GSL/2.7\n",
      " 21) OpenSSL/1.1                 53) NCO/5.1.3\n",
      " 22) gzip/.1.12             (H)  54) libarchive/3.6.1\n",
      " 23) lz4/.1.9.3             (H)  55) CMake/3.23.1\n",
      " 24) zstd/.1.5.2            (H)  56) gettext/.0.21        (H)\n",
      " 25) bzip2/.1.0.8           (H)  57) DB/.18.1.40          (H)\n",
      " 26) JasPer/.2.0.33         (H)  58) XML-LibXML/.2.0207   (H)\n",
      " 27) NASM/.2.15.05          (H)  59) DB_File/.1.858       (H)\n",
      " 28) libjpeg-turbo/.2.1.3   (H)  60) BioPerl/1.7.8\n",
      " 29) libpng/.1.6.37         (H)  61) Perl-JSC-extra/2022a\n",
      " 30) libaec/1.0.6                62) Perl/5.34.1\n",
      " 31) ecCodes/2.27.0              63) git/2.36.0-nodocs\n",
      " 32) HDF5/1.12.2\n",
      "\n",
      "  Where:\n",
      "   H:  Hidden Module\n",
      "   S:  Module is Sticky, requires --force to unload or purge\n",
      "   g:  Built with GPU support\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Currently Loaded Modules:\n",
      "  1) Stages/2023            (S)  33) netCDF/4.9.0\n",
      "  2) GCCcore/.11.3.0        (H)  34) netCDF-Fortran/4.6.0\n",
      "  3) zlib/.1.2.12           (H)  35) PnetCDF/1.12.3\n",
      "  4) binutils/.2.38         (H)  36) cURL/7.83.0\n",
      "  5) Intel/2022.1.0              37) Szip/.2.1.1          (H)\n",
      "  6) numactl/2.0.15              38) ncurses/.6.3         (H)\n",
      "  7) nvidia-driver/.default (H)  39) libreadline/.8.1.2   (H)\n",
      "  8) CUDA/11.7              (g)  40) SQLite/.3.38.3       (H)\n",
      "  9) UCX-settings/RC             41) GMP/6.2.1\n",
      " 10) UCX/default            (g)  42) libffi/.3.4.2        (H)\n",
      " 11) pscom/.5.6-default     (H)  43) Python/3.10.4\n",
      " 12) XZ/.5.2.5              (H)  44) expat/.2.4.8         (H)\n",
      " 13) libxml2/.2.9.13        (H)  45) UDUNITS/.2.2.28      (H)\n",
      " 14) MPI-settings/UCX            46) Java/11.0.16\n",
      " 15) ParaStationMPI/5.7.0-1 (g)  47) ANTLR/.2.7.7         (H)\n",
      " 16) imkl/2022.1.0               48) libtirpc/.1.3.2      (H)\n",
      " 17) imkl-FFTW/2022.1.0          49) PCRE/.8.45           (H)\n",
      " 18) Hypre/2.27.0-cpu            50) util-linux/.2.38     (H)\n",
      " 19) Silo/4.11                   51) libdap/.3.20.11      (H)\n",
      " 20) Tcl/8.6.12                  52) GSL/2.7\n",
      " 21) OpenSSL/1.1                 53) NCO/5.1.3\n",
      " 22) gzip/.1.12             (H)  54) libarchive/3.6.1\n",
      " 23) lz4/.1.9.3             (H)  55) CMake/3.23.1\n",
      " 24) zstd/.1.5.2            (H)  56) gettext/.0.21        (H)\n",
      " 25) bzip2/.1.0.8           (H)  57) DB/.18.1.40          (H)\n",
      " 26) JasPer/.2.0.33         (H)  58) XML-LibXML/.2.0207   (H)\n",
      " 27) NASM/.2.15.05          (H)  59) DB_File/.1.858       (H)\n",
      " 28) libjpeg-turbo/.2.1.3   (H)  60) BioPerl/1.7.8\n",
      " 29) libpng/.1.6.37         (H)  61) Perl-JSC-extra/2022a\n",
      " 30) libaec/1.0.6                62) Perl/5.34.1\n",
      " 31) ecCodes/2.27.0              63) git/2.36.0-nodocs\n",
      " 32) HDF5/1.12.2\n",
      "\n",
      "  Where:\n",
      "   H:  Hidden Module\n",
      "   S:  Module is Sticky, requires --force to unload or purge\n",
      "   g:  Built with GPU support\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Currently Loaded Modules:\n",
      "  1) Stages/2023            (S)  33) netCDF/4.9.0\n",
      "  2) GCCcore/.11.3.0        (H)  34) netCDF-Fortran/4.6.0\n",
      "  3) zlib/.1.2.12           (H)  35) PnetCDF/1.12.3\n",
      "  4) binutils/.2.38         (H)  36) cURL/7.83.0\n",
      "  5) Intel/2022.1.0              37) Szip/.2.1.1          (H)\n",
      "  6) numactl/2.0.15              38) ncurses/.6.3         (H)\n",
      "  7) nvidia-driver/.default (H)  39) libreadline/.8.1.2   (H)\n",
      "  8) CUDA/11.7              (g)  40) SQLite/.3.38.3       (H)\n",
      "  9) UCX-settings/RC             41) GMP/6.2.1\n",
      " 10) UCX/default            (g)  42) libffi/.3.4.2        (H)\n",
      " 11) pscom/.5.6-default     (H)  43) Python/3.10.4\n",
      " 12) XZ/.5.2.5              (H)  44) expat/.2.4.8         (H)\n",
      " 13) libxml2/.2.9.13        (H)  45) UDUNITS/.2.2.28      (H)\n",
      " 14) MPI-settings/UCX            46) Java/11.0.16\n",
      " 15) ParaStationMPI/5.7.0-1 (g)  47) ANTLR/.2.7.7         (H)\n",
      " 16) imkl/2022.1.0               48) libtirpc/.1.3.2      (H)\n",
      " 17) imkl-FFTW/2022.1.0          49) PCRE/.8.45           (H)\n",
      " 18) Hypre/2.27.0-cpu            50) util-linux/.2.38     (H)\n",
      " 19) Silo/4.11                   51) libdap/.3.20.11      (H)\n",
      " 20) Tcl/8.6.12                  52) GSL/2.7\n",
      " 21) OpenSSL/1.1                 53) NCO/5.1.3\n",
      " 22) gzip/.1.12             (H)  54) libarchive/3.6.1\n",
      " 23) lz4/.1.9.3             (H)  55) CMake/3.23.1\n",
      " 24) zstd/.1.5.2            (H)  56) gettext/.0.21        (H)\n",
      " 25) bzip2/.1.0.8           (H)  57) DB/.18.1.40          (H)\n",
      " 26) JasPer/.2.0.33         (H)  58) XML-LibXML/.2.0207   (H)\n",
      " 27) NASM/.2.15.05          (H)  59) DB_File/.1.858       (H)\n",
      " 28) libjpeg-turbo/.2.1.3   (H)  60) BioPerl/1.7.8\n",
      " 29) libpng/.1.6.37         (H)  61) Perl-JSC-extra/2022a\n",
      " 30) libaec/1.0.6                62) Perl/5.34.1\n",
      " 31) ecCodes/2.27.0              63) git/2.36.0-nodocs\n",
      " 32) HDF5/1.12.2\n",
      "\n",
      "  Where:\n",
      "   H:  Hidden Module\n",
      "   S:  Module is Sticky, requires --force to unload or purge\n",
      "   g:  Built with GPU support\n",
      "\n",
      " \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still running (['20190501-20190531', 'i000', 'R000'])...\n",
      "Still running (['20190501-20190531', 'i000', 'R003'])...\n",
      "Submitted batch job 10183394\n",
      "Submitted batch job 10183395\n",
      "Submitted batch job 10183396\n",
      "Still running (['20190501-20190531', 'i000', 'R001'])...\n",
      "Still running (['20190501-20190531', 'i000', 'R000'])...Still running (['20190501-20190531', 'i000', 'R003'])...\n",
      "\n",
      "Still running (['20190501-20190531', 'i000', 'R001'])...\n",
      "Still running (['20190501-20190531', 'i000', 'R000'])...\n",
      "Still running (['20190501-20190531', 'i000', 'R003'])...\n",
      "Still running (['20190501-20190531', 'i000', 'R001'])...\n"
     ]
    }
   ],
   "source": [
    "with mp.Pool(processes=n_parallel) as pool:\n",
    "    pool.starmap(setup_submit_wait, zip(np.arange(0,n_ensemble+1),repeat(settings_run),repeat(settings_clm),\n",
    "                                       repeat(settings_pfl),repeat(settings_sbatch),repeat(date_results_iter),repeat(n_ensemble)) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd0fc314-5fb4-49c8-9e98-9c245cb438e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Timestamp('2019-03-02 20:00:00'), Timestamp('2019-05-01 20:00:00')],\n",
       " [Timestamp('2019-05-01 20:00:00', freq='3D'),\n",
       "  Timestamp('2019-05-04 20:00:00', freq='3D'),\n",
       "  Timestamp('2019-05-07 20:00:00', freq='3D'),\n",
       "  Timestamp('2019-05-10 20:00:00', freq='3D'),\n",
       "  Timestamp('2019-05-13 20:00:00', freq='3D'),\n",
       "  Timestamp('2019-05-16 20:00:00', freq='3D'),\n",
       "  Timestamp('2019-05-19 20:00:00', freq='3D'),\n",
       "  Timestamp('2019-05-22 20:00:00', freq='3D'),\n",
       "  Timestamp('2019-05-25 20:00:00', freq='3D'),\n",
       "  Timestamp('2019-05-28 20:00:00', freq='3D'),\n",
       "  Timestamp('2019-05-31 20:00:00', freq='3D')]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_results_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "14df4fb3-3592-463e-a6e7-2ffc3a02a8b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/p/scratch/cjibg36/jibg3674/CLM5_DA/small_test_ap/input_clm/datm.streams.solar_noise.stream']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_setup = settings_run['dir_setup']\n",
    "files_stream_n = glob(os.path.join(dir_setup,'input_clm/*streams*noise*'))\n",
    "files_stream_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20885f2a-5a95-468b-9ce1-b6d6536eab73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has been updated and saved to datm_out\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define the file paths\n",
    "input_file_path = 'datm_in'  # Replace with the path to your input file\n",
    "output_file_path = 'datm_out'  # Replace with the path where you want to save the modified file\n",
    "\n",
    "# Read the content of the file\n",
    "with open(input_file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "year = 2019\n",
    "\n",
    "# Define the new streams lines to be added\n",
    "new_streams_lines = (\n",
    "    f\"\\n           'datm.streams.solar_noise.stream {year} {year} {year}',\\n\"\n",
    "    f\"           'datm.streams.precip_noise.stream {year} {year} {year}',\\n\"\n",
    "    f\"           'datm.streams.other_noise.stream {year} {year} {year}'\"\n",
    ")\n",
    "\n",
    "# Find the position to insert the new streams\n",
    "match = re.search(r\"streams = (.*?)(\\s*taxmode)\", content, re.DOTALL)\n",
    "if match:\n",
    "    before_streams = match.group(1)\n",
    "    after_streams = match.group(2)\n",
    "    # Insert the new lines into the streams section\n",
    "    new_content = content.replace(before_streams, before_streams + new_streams_lines)\n",
    "\n",
    "# Write the modified content to the output file\n",
    "with open(output_file_path, 'w') as file:\n",
    "    file.write(new_content)\n",
    "\n",
    "print(f\"File has been updated and saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09678a80-6d24-481e-a6d4-be70a539e9d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_ensemble, reread_required = check_for_success(dir_iter,dir_DA,dir_settings,date_results_iter,n_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502b15a7-15ab-4569-bb76-8b5a04768af8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import DA_operators\n",
    "importlib.reload(DA_operators)\n",
    "from DA_operators import operator_clm_SMAP, operator_clm_FLX\n",
    "\n",
    "operator = {}\n",
    "data_measured = {}\n",
    "data_latlon = {}\n",
    "\n",
    "# Operator for SMAP\n",
    "operator['SMAP'] = operator_clm_SMAP(settings_DA['file_lsm'],settings_DA['file_corner'],settings_DA['folder_SMAP'],ignore_rivers=False)\n",
    "data_measured['SMAP'],_,data_latlon['SMAP'] = operator['SMAP'].get_measurements(date_results_iter,date_DA_start=date_start_sim,return_latlon=True)\n",
    "\n",
    "# Operator for FLUXNET\n",
    "operator['FLX'] = operator_clm_FLX(settings_DA['file_lsm'],settings_DA['file_corner'],settings_DA['folder_FLX'],ignore_rivers=False)\n",
    "data_measured['FLX'],data_var['FLX'],data_latlon['FLX'] = operator['FLX'].get_measurements(date_results_iter,date_DA_start=date_start_sim,return_latlon=True,variance=settings_DA['data_var']['FLX'])\n",
    "\n",
    "# mask observations to required amount given in data_nselect\n",
    "# it would be more efficient to already apply the masking in the operator.get_measurements functions\n",
    "data_mask,data_indices,n_data,data_measured_masked,data_var_masked,data_latlon_masked = mask_observations(data_names,data_measured,data_var,data_latlon,data_nselect,data_mask,factor_inflate=factor_inflate)\n",
    "\n",
    "# get most likely parameter output, to track if the iterations are improving\n",
    "t0 = time.time()\n",
    "_ = operator['SMAP'].interpolate_model_results(0,settings_run,indices_z=[0,1],var='SOILLIQ')#[data_mask['SMAP']]\n",
    "operator['SMAP'].plot_results(i_iter,0,settings_run,indices_z=0,var='SOILLIQ',n_plots=12,dir_figs=settings_run['dir_figs'])\n",
    "_ = operator['FLX'].interpolate_model_results(0,settings_run,retain_history=True)#[data_mask['FLX']]\n",
    "operator['FLX'].plot_results(i_iter,0,settings_run,dir_figs=os.path.join(settings_run['dir_figs'],'FLX'))\n",
    "t1 = time.time()\n",
    "print('%f seconds for interpolating/plotting one ensemble member'%(t1-t0), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247507f0-cfa5-4262-996a-15781e9588b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2) get the corresponding ensemble measurements (\"forecast\")\n",
    "print('Interpolating/plotting all ensemble members...', flush=True)\n",
    "t0 = time.time()\n",
    "data_f = np.zeros([n_data,n_ensemble])\n",
    "for i_real in np.arange(1,n_ensemble+1):   \n",
    "    print('%i/%i' % (i_real,n_ensemble), flush=True)\n",
    "    for var_ in data_names:\n",
    "        data_f[data_indices[var_][0]:data_indices[var_][1],i_real-1] = operator[var_].interpolate_model_results(i_real,settings_run)[data_mask[var_]]\n",
    "    if 'SMAP' in data_names and (plot_members_SMAP==True or plot_members_SMAP==i_iter):\n",
    "        operator['SMAP'].plot_results(i_iter,i_real,settings_run,indices_z=0,var='SOILLIQ',n_plots=4)\n",
    "t1 = time.time()\n",
    "print('%f seconds for interpolating/plotting all ensemble members'%(t1-t0), flush=True)\n",
    "print('Shape of data array (data_f):')\n",
    "print(data_f.shape)\n",
    "\n",
    "if 'FLX' in data_names and plot_members_FLX:\n",
    "    operator['FLX'].plot_all_results(i_iter,settings_run,dir_figs=os.path.join(settings_run['dir_figs'],'FLX'))\n",
    "\n",
    "print('Performing Kalman update...', flush=True)\n",
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7f34e6-2a67-4c00-a085-ae5473609689",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_a,mean_mismatch_new,alpha = update_step_ESMDA_loc(param_f,data_f,data_measured_masked,data_var_masked,alpha,i_iter,n_iter,\n",
    "                                                        param_latlon=param_latlon,param_r_loc=param_r_loc,data_latlon=data_latlon_masked,ksi=ksi,\n",
    "                                                        dir_settings=dir_settings,dzeta_global=settings_DA['dzeta_global'],\n",
    "                                                        factor_inflate_prior=factor_inflate_prior,\n",
    "                                                        loc_type=settings_DA['loc_type'],POL_eps=settings_DA['POL_eps'])\n",
    "t1 = time.time()\n",
    "print('%f seconds for Kalman update'%(t1-t0), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f61742d-6b6e-41ca-b78e-43ee3b23faef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f75916-5ba5-4aa9-8e62-f9a4857db2d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test for func 'update_step_ESMDA_loc'\n",
    "\n",
    "mat_M = param_f\n",
    "mat_D = data_f\n",
    "data_measured = data_measured_masked\n",
    "data_var = data_var_masked\n",
    "alpha = [27269.372843216566, 1.000036636127625]\n",
    "i_iter = 0\n",
    "n_iter = 2\n",
    "\n",
    "n_data_ = mat_D.shape[0]\n",
    "n_ensemble = mat_D.shape[1]\n",
    "n_param = mat_M.shape[0]\n",
    "\n",
    "C_D = sparse.diags(data_var)\n",
    "\n",
    "del_M = (1/np.sqrt(n_ensemble-1))*(mat_M - mat_M.mean(axis=1)[:,np.newaxis])\n",
    "del_D = (1/np.sqrt(n_ensemble-1))*(mat_D - mat_D.mean(axis=1)[:,np.newaxis])\n",
    "\n",
    "del_D *= factor_inflate_prior\n",
    "\n",
    "S = sparse.diags(C_D.diagonal()**(1/2))\n",
    "C_Dh = 1.*sparse.eye(n_data_)\n",
    "Sinv = sparse.diags(1/S.diagonal()) #inverse of diagonal matrix: simply the reciprocal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46d8980-e191-4a3f-9749-506d07b0f9b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Ud, lambda_Wd, Vdt = np.linalg.svd(Sinv.dot(del_D), full_matrices=False)\n",
    "assert(np.all(lambda_Wd[:-1] > lambda_Wd[1:]))\n",
    "       \n",
    "cumsum_wr = np.cumsum(lambda_Wd) / np.sum(lambda_Wd)\n",
    "Nr = max(len(lambda_Wd)//2, np.where(cumsum_wr<=ksi)[0][-1]) #take Nr most important singular values, retain at least half the original matrix size just in case\n",
    "\n",
    "Ur = Ud[:,0:Nr]\n",
    "Wr = sparse.diags(lambda_Wd[0:Nr])\n",
    "Vrt = Vdt[0:Nr,0:Nr]\n",
    "Ir = sparse.eye(Nr)\n",
    "Wrinv = sparse.diags(1/Wr.diagonal()) \n",
    "\n",
    "mat_R = alpha[i_iter]*(Wrinv @ Ur.T @ C_Dh @ Ur @ Wrinv)\n",
    "\n",
    "Zr, lambda_Hr, Zrt = np.linalg.svd(mat_R, full_matrices=False)\n",
    "Hr = sparse.diags(lambda_Hr)\n",
    "\n",
    "mat_X = Sinv @ Ur @ Wrinv @ Zr\n",
    "mat_L = Ir + Hr\n",
    "mat_Linv = sparse.diags(1/mat_L.diagonal()) \n",
    "\n",
    "mat_X1 = mat_Linv @ mat_X.T\n",
    "mat_X2 = del_D.T @ mat_X\n",
    "mat_X3 = mat_X2 @ mat_X1\n",
    "\n",
    "# perturb observations, at the same time calculate the mismatch of the current forecast\n",
    "mat_Dobs = np.zeros(mat_D.shape)\n",
    "mean_mismatch_new = 0\n",
    "for i_real in range(n_ensemble):\n",
    "    z_d = np.random.normal(0,1,n_data_)\n",
    "    mat_Dobs[:,i_real] = data_measured + np.sqrt(alpha[i_iter])*np.sqrt(C_D.diagonal())*z_d\n",
    "    mismatch = mat_Dobs[:,i_real] - mat_D[:,i_real]\n",
    "    mean_mismatch_new += np.sum(mismatch**2)\n",
    "mean_mismatch_new /= n_ensemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676ad47c-41f6-47ca-98cd-10b2b42015d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_d_localized = 0\n",
    "sum_d_global = 0\n",
    "n_param_localized_tot = 0\n",
    "# calculate updated (analysis) parameters\n",
    "\n",
    "# used for POL localisation:\n",
    "c_ii = np.var( (mat_M - mat_M.mean(axis=1)[:,np.newaxis]), axis=1, ddof=1) #(n_param,) -> estimate of C_M\n",
    "c_jj = np.var( (mat_D - mat_D.mean(axis=1)[:,np.newaxis]), axis=1, ddof=1) #(n_data,) -> estimate of C_D\n",
    "\n",
    "param_a = np.zeros(mat_M.shape)\n",
    "for i in range(n_param):\n",
    "\n",
    "    # first localisation option: distance based, by using haversine distance & GC function\n",
    "    if loc_type == 'distance':    \n",
    "        if np.isnan(param_r_loc[i]):\n",
    "            rho_i = dzeta_global*np.ones(n_data_) #no localisation\n",
    "        else:\n",
    "            r_loc = param_r_loc[i]\n",
    "            # localisation using the Gaspari-Cohn localisation function:\n",
    "            rho_i = GC(haversine_distance(param_latlon[i,:],data_latlon),r_loc)\n",
    "    # second option: pseudo optimal localization\n",
    "    # see e.g. Lacerda et al. (2019), Furrer et al. (2007)\n",
    "    elif loc_type == 'POL':\n",
    "        ci = del_M[i,:]@(del_D[:,:].T)\n",
    "        rho_i = ci**2 / (ci**2 + (ci**2+(c_ii[i]*c_jj)/n_ensemble) )\n",
    "        mask_zero = np.abs(ci) < POL_eps*np.sqrt(c_ii[i]*c_jj)\n",
    "        rho_i[mask_zero] = 0\n",
    "\n",
    "    else:\n",
    "        print('Warning!! Localisation method unknown. Set to POL or distance')\n",
    "        rho_i = np.ones(n_data_)\n",
    "\n",
    "\n",
    "    K_i = del_M[i,:]@mat_X3\n",
    "    K_rho_i = K_i * rho_i\n",
    "    mat_X4 = K_rho_i @ (mat_Dobs - mat_D)\n",
    "    param_a[i,:] = mat_M[i,:] + mat_X4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4015041d-735d-4dc4-9c59-4a25d58a7ccd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del_M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a0e458-5786-4d9e-94d9-5948d7a57aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83325a1-9496-482d-910c-b0f24151276e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "settings_run['dir_iter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fd041f-bd4f-41b8-a2ca-7214929fc2ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files_clm = sorted(glob(os.path.join(settings_run['dir_iter'],'R000/**/*.clm2.h0.*.nc')))\n",
    "print(files_clm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5380405a-1956-4e6e-9717-da40961507bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_centre = xr.open_dataset('/p/project/cjibg36/jibg3674/shared_DA/EUR-11_TSMP_FZJ-IBG3_444x432_LAND-LAKE-SEA-MASK.nc',decode_times=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144533ca-43a7-46f5-87d3-b5195e2387c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid_centre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7726d5a-c598-4939-8556-7551b7e03478",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid_centre.lon.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919c1e1c-6152-4675-b90e-c2117714705a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid_corner = xr.open_dataset('/p/project/cjibg36/jibg3674/shared_DA/EUR-11_444x432_corners_curvi_Tair.nc')\n",
    "lon_edges = np.concatenate((grid_corner.lon.values[:,-1],grid_corner.lon.values[:,0],grid_corner.lon.values[0,:],grid_corner.lon.values[-1,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb4ed69-a8fb-498b-bb70-8e9f564c557c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lon_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f190c67-8d8b-4756-a60a-29c4a766b198",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
